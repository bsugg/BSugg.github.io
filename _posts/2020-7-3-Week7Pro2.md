---
layout: post
title: Week 7 - Project 2
---

#### _Once you’ve completed your tasks you should write a brief blog post outlining your project and the findings you made. You should also reflect on the process you went through for this project. Discuss things like:_
- What would you do differently?  
- What was the most difficult part for you?  
- What are your big take-aways from this project?  

[Link to Project 2 Submission on GitHub Pages](https://bsugg.github.io/Project2/)  

In brief summary, the development of my markdown files for Project 2 was a good learning experience overall. I tried to stay methodical in the development process, starting with exploring the data we were asked to analyze and how the original authors approached the challenge of predicting article popularity. As with any analysis project, I think understanding the data you are working with is critical for success later on when determining which predictor variables to use, their potential correlations, and overall effect on the response variable when evaluating accuracy and misclassification rates. After the exploration phase, I then considered which linear and non-linear models I would incorporate into the project. After learning the original authors found Random Forests to be their best predictor, I wanted to try that as my non-linear model. For the linear model, logistic regression seemed like the logical fit for predicting a binary value for article popularity. After having an idea of which model types to pursue, I followed the suggested approach in the assignment ... data importing, cleansing, slicing, fitting a model, model selection, and analyzing the prediction results on the test data set.  

If I could go back and do one thing differently, it would be using another non-linear model type instead of Random Forests, which was painfully expensive from a computational perspective and resulting waiting time. I tested many combinations of folds and resampling amounts with my k-fold cross validation for Random Forests to determine a realistic number for these parameters. Ideally, I wanted a combination of lower folds and resampling repetition that would give similar accuracy numbers to higher folds, without waiting 2+ hours when the final fitting was run for all 7 days of the week.  

The most difficult part of this assignment, which I initially thought would be the easiest, was automating the RMarkdown for one template to generate 7 different files. There was a lot of trial and error with understanding one .rmd file cannot serve as both your README and Template, and finding the right package/functions to use for the automation itself. I did enjoy the final solution I used, however, with the `map()` function inside the `purrr` package. It seemed simpler than what I was trying to replicate from the class notes, and required less code. Now that I understand the process, I look forward to applying it to another exercise in the future!! The value of automation is clear.  

My biggest take-aways, in addition to my experiences with Random Forests and automating RMarkdown, is how incredibly simple the `caret` package is from a user's perspective when it comes to model fitting and selection. In my exploration phase for this project I did a lot of reading on the 100+ types of models that can be applied with the `train()` function. It's a package I'm looking forward to using beyond this class, and I'm happy to have it in my R toolkit.  

In conclusion, my analysis in this project showed better accuracy and misclassification rate for the Random Forests models in 6 out of the 7 days of the week when compared to the Logistic Regression model. Saturday predictions even had an accuracy value as high as 0.7414! No surprise after reading the findings from the original experiment that this project was derived from, but it would be interesting if I could go back and try fitting additional types of linear and non-linear methods for comparison. It would also be interesting to try predicting the actual number of shares instead of a binary value for popularity. I initially tried predicting the number of shares with a linear model, but the accuracy was not as high as the results from predicting popularity. So I decided at an earlier stage to change the prediction focus of my project to popularity instead of number of shares.  
